{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DIAT_CNN_Labs.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMvmDLCIF5P1SAYVOI1uzoa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vinayex2/courses/blob/master/DIAT_CNN_Labs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QgSBm9VAkrU5"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-VXA_HX0k3zD",
        "outputId": "50f6366d-b7ea-4555-f67a-cbc1fb59babb"
      },
      "source": [
        "(x_train,y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RZxqg568lSz7",
        "outputId": "28448662-bbd2-4a62-bc39-75a5bda18ea9"
      },
      "source": [
        "print(f'Train Shape {x_train.shape} and Y Shape is {y_train.shape}')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Shape (60000, 28, 28) and Y Shape is (60000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "p-_Uww_wlgna",
        "outputId": "0a67d812-7d3a-45db-8972-4101a2e15aca"
      },
      "source": [
        "plt.imshow(x_train[1,:,:])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fb31b7bc410>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4qqVJTVul08-"
      },
      "source": [
        "fashion_mnist_labels = [\n",
        "                        't-shirt/top',\n",
        "                        'trouser',\n",
        "                        'pullover',\n",
        "                        'dress',\n",
        "                        'coat',\n",
        "                        'sandal',\n",
        "                        'shirt',\n",
        "                        'sneaker',\n",
        "                        'bag',\n",
        "                        'ankle boot'                        \n",
        "]"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "UA958R949Xan",
        "outputId": "295f368d-4853-4a07-a3a1-f58df18c9ed0"
      },
      "source": [
        "img_index = 5\n",
        "label_index = y_train[img_index]\n",
        "print(f'Y is {label_index} and label is {fashion_mnist_labels[label_index]}')\n",
        "plt.imshow(x_train[img_index,:,:])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Y is 2 and label is pullover\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fb31b73add0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gx00sS2e-Fma"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jArDtOEh-p4b"
      },
      "source": [
        "Further break training into Train and Validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HN-tutzz-xeC"
      },
      "source": [
        "(x_train, x_valid) = x_train[5000:], x_train[:5000]\n",
        "(y_train, y_valid) = y_train[5000:], y_train[:5000]"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IKGfhcdp-9Ai"
      },
      "source": [
        "#Reshape input from (28,28) to (28,28,1)\n",
        "w,h = 28,28\n",
        "x_train = x_train.reshape(x_train.shape[0],w,h,1)\n",
        "x_valid = x_valid.reshape(x_valid.shape[0],w,h,1)\n",
        "x_test = x_test.reshape(x_test.shape[0],w,h,1)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-WtTQIms_Uza"
      },
      "source": [
        "#One Hot Encoding for labels\n",
        "y_train = tf.keras.utils.to_categorical(y_train,10)\n",
        "y_valid = tf.keras.utils.to_categorical(y_valid,10)\n",
        "y_test = tf.keras.utils.to_categorical(y_test,10)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BOH9KwgS_hzC",
        "outputId": "98978562-2f3e-447d-c2e6-17ef11a477f3"
      },
      "source": [
        "print(f'X_train shape {x_train.shape} and y shape {y_train.shape}')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train shape (55000, 28, 28, 1) and y shape (55000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VDv63bBA_p9i",
        "outputId": "d25a9ec8-081d-4894-cd8d-c9a0792e542b"
      },
      "source": [
        "print(f'Length of Train, Valid and Test is {x_train.shape[0]}, {x_valid.shape[0]} and {x_test.shape[0]}')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of Train, Valid and Test is 55000, 5000 and 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UzuiBuuVAgeA"
      },
      "source": [
        "Building **LeNet** Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R7C9DEPlAksq"
      },
      "source": [
        "def build_lenet_model():\n",
        "  model = tf.keras.Sequential()\n",
        "  #Must define input shape in first layer of NN\n",
        "  model.add(tf.keras.layers.Conv2D(filters=6,\n",
        "                                   kernel_size=5,\n",
        "                                   activation='sigmoid',\n",
        "                                   padding= 'same',\n",
        "                                   input_shape = (28,28,1)))\n",
        "  #Avg Pooling with strides\n",
        "  model.add(tf.keras.layers.AvgPool2D(pool_size=2,\n",
        "                                      strides=2))\n",
        "  \n",
        "  model.add(tf.keras.layers.Conv2D(filters=16,\n",
        "                                   kernel_size=5,\n",
        "                                   activation='sigmoid'))\n",
        "  \n",
        "  model.add(tf.keras.layers.AvgPool2D(pool_size=2,\n",
        "                                      strides=2))\n",
        "  \n",
        "  model.add(tf.keras.layers.Flatten())\n",
        "  model.add(tf.keras.layers.Dense(120, activation = 'sigmoid'))\n",
        "  model.add(tf.keras.layers.Dense(84, activation = 'sigmoid'))\n",
        "  model.add(tf.keras.layers.Dense(10, activation = 'softmax'))\n",
        "\n",
        "  model.compile(loss = 'categorical_crossentropy',\n",
        "                optimizer='adam',\n",
        "                metrics=['accuracy'])\n",
        "  \n",
        "  return model\n",
        "  \n",
        "  "
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vk9pLS_7Bo3N",
        "outputId": "70110fbf-92b3-4f9c-8ace-f68caa4b29ad"
      },
      "source": [
        "le_net = build_lenet_model()\n",
        "print(le_net.summary())"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_4 (Conv2D)            (None, 28, 28, 6)         156       \n",
            "_________________________________________________________________\n",
            "average_pooling2d_4 (Average (None, 14, 14, 6)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 10, 10, 16)        2416      \n",
            "_________________________________________________________________\n",
            "average_pooling2d_5 (Average (None, 5, 5, 16)          0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 400)               0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 120)               48120     \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 84)                10164     \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 10)                850       \n",
            "=================================================================\n",
            "Total params: 61,706\n",
            "Trainable params: 61,706\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DJj9ir-jCW_c"
      },
      "source": [
        "Model Checkpointing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GmTRqI7uCYva",
        "outputId": "3f79f928-a99c-4f46-cb57-29c63a5f1ea4"
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint\n",
        "checkpoint = ModelCheckpoint(filepath='model.weights.best.hdf5',\n",
        "                             verbose=1,\n",
        "                             save_best_only=True)\n",
        "model_log = le_net.fit(x_train,\n",
        "                      y_train,\n",
        "                      batch_size=64,\n",
        "                      epochs=10,\n",
        "                      validation_data = (x_valid,y_valid),\n",
        "                      callbacks = [checkpoint])"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "860/860 [==============================] - 35s 40ms/step - loss: 1.3986 - accuracy: 0.4982 - val_loss: 0.5790 - val_accuracy: 0.7810\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.57904, saving model to model.weights.best.hdf5\n",
            "Epoch 2/10\n",
            "860/860 [==============================] - 35s 40ms/step - loss: 0.5684 - accuracy: 0.7773 - val_loss: 0.4560 - val_accuracy: 0.8272\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.57904 to 0.45602, saving model to model.weights.best.hdf5\n",
            "Epoch 3/10\n",
            "860/860 [==============================] - 35s 40ms/step - loss: 0.4740 - accuracy: 0.8218 - val_loss: 0.4035 - val_accuracy: 0.8530\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.45602 to 0.40347, saving model to model.weights.best.hdf5\n",
            "Epoch 4/10\n",
            "860/860 [==============================] - 35s 41ms/step - loss: 0.4185 - accuracy: 0.8447 - val_loss: 0.3794 - val_accuracy: 0.8570\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.40347 to 0.37939, saving model to model.weights.best.hdf5\n",
            "Epoch 5/10\n",
            "860/860 [==============================] - 35s 41ms/step - loss: 0.3938 - accuracy: 0.8534 - val_loss: 0.3613 - val_accuracy: 0.8622\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.37939 to 0.36127, saving model to model.weights.best.hdf5\n",
            "Epoch 6/10\n",
            "860/860 [==============================] - 35s 40ms/step - loss: 0.3647 - accuracy: 0.8632 - val_loss: 0.3445 - val_accuracy: 0.8690\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.36127 to 0.34452, saving model to model.weights.best.hdf5\n",
            "Epoch 7/10\n",
            "860/860 [==============================] - 34s 40ms/step - loss: 0.3440 - accuracy: 0.8719 - val_loss: 0.3269 - val_accuracy: 0.8812\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.34452 to 0.32690, saving model to model.weights.best.hdf5\n",
            "Epoch 8/10\n",
            "860/860 [==============================] - 35s 41ms/step - loss: 0.3360 - accuracy: 0.8743 - val_loss: 0.3077 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 00008: val_loss improved from 0.32690 to 0.30766, saving model to model.weights.best.hdf5\n",
            "Epoch 9/10\n",
            "860/860 [==============================] - 35s 41ms/step - loss: 0.3176 - accuracy: 0.8825 - val_loss: 0.3193 - val_accuracy: 0.8824\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 0.30766\n",
            "Epoch 10/10\n",
            "860/860 [==============================] - 35s 40ms/step - loss: 0.3143 - accuracy: 0.8844 - val_loss: 0.2956 - val_accuracy: 0.8910\n",
            "\n",
            "Epoch 00010: val_loss improved from 0.30766 to 0.29560, saving model to model.weights.best.hdf5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lp6_jf7cC8F-",
        "outputId": "b459584c-bd9b-422c-8421-e97a39e124ff"
      },
      "source": [
        "score  = le_net.evaluate(x_test,y_test)\n",
        "print(f'Test Accuracy is {score[1]}')"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 4s 12ms/step - loss: 0.3312 - accuracy: 0.8786\n",
            "Test Accuracy is 0.878600001335144\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U6S-f4SsEaTj"
      },
      "source": [
        "Improving on **Le Net**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRF2atXgEZ-3"
      },
      "source": [
        "def build_lenet_model_variant():\n",
        "  model = tf.keras.Sequential()\n",
        "  #Must define input shape in first layer of NN\n",
        "  model.add(tf.keras.layers.Conv2D(filters=64,\n",
        "                                   kernel_size=2,\n",
        "                                   activation='relu',\n",
        "                                   padding= 'same',\n",
        "                                   input_shape = (28,28,1)))\n",
        "  #Avg Pooling with strides\n",
        "  model.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
        "  model.add(tf.keras.layers.Dropout(0.3))\n",
        "  \n",
        "  model.add(tf.keras.layers.Conv2D(filters=32,\n",
        "                                   kernel_size=2,\n",
        "                                   padding= 'same',\n",
        "                                   activation='relu'))\n",
        "  model.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
        "  model.add(tf.keras.layers.Dropout(0.3))  \n",
        "  \n",
        "  model.add(tf.keras.layers.Flatten())\n",
        "  \n",
        "  '''We need bigger fully connected layer as Output shape from flattened\n",
        "  Convolutions  is 1568'''\n",
        "\n",
        "  model.add(tf.keras.layers.Dense(256, activation = 'relu'))\n",
        "  model.add(tf.keras.layers.Dropout(0.5))   \n",
        "  model.add(tf.keras.layers.Dense(10, activation = 'softmax'))\n",
        "\n",
        "  model.compile(loss = 'categorical_crossentropy',\n",
        "                optimizer='adam',\n",
        "                metrics=['accuracy'])\n",
        "  \n",
        "  return model"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "stQxsw6ZFjSG",
        "outputId": "fabc7bc0-ade5-484b-b092-8d6e3d3c4679"
      },
      "source": [
        "le_net_variant = build_lenet_model_variant()\n",
        "print(le_net_variant.summary())\n"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_6 (Conv2D)            (None, 28, 28, 64)        320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 14, 14, 32)        8224      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 7, 7, 32)          0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 7, 7, 32)          0         \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 1568)              0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 256)               401664    \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 10)                2570      \n",
            "=================================================================\n",
            "Total params: 412,778\n",
            "Trainable params: 412,778\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WQMrGUMDFwhC",
        "outputId": "a14b1bcb-5376-4a01-d83e-da97e2e9ba06"
      },
      "source": [
        "checkpoint = ModelCheckpoint(filepath='model_v2.weights.best.hdf5',\n",
        "                             verbose=1,\n",
        "                             save_best_only=True)\n",
        "model_log = le_net_variant.fit(x_train,\n",
        "                      y_train,\n",
        "                      batch_size=64,\n",
        "                      epochs=10,\n",
        "                      validation_data = (x_valid,y_valid),\n",
        "                      callbacks = [checkpoint])"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "860/860 [==============================] - 62s 72ms/step - loss: 4.7957 - accuracy: 0.5649 - val_loss: 0.4960 - val_accuracy: 0.8186\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.49598, saving model to model_v2.weights.best.hdf5\n",
            "Epoch 2/10\n",
            "860/860 [==============================] - 61s 71ms/step - loss: 0.6296 - accuracy: 0.7643 - val_loss: 0.4280 - val_accuracy: 0.8450\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.49598 to 0.42803, saving model to model_v2.weights.best.hdf5\n",
            "Epoch 3/10\n",
            "860/860 [==============================] - 62s 72ms/step - loss: 0.5393 - accuracy: 0.7963 - val_loss: 0.3718 - val_accuracy: 0.8648\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.42803 to 0.37185, saving model to model_v2.weights.best.hdf5\n",
            "Epoch 4/10\n",
            "860/860 [==============================] - 61s 71ms/step - loss: 0.4887 - accuracy: 0.8210 - val_loss: 0.3407 - val_accuracy: 0.8760\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.37185 to 0.34065, saving model to model_v2.weights.best.hdf5\n",
            "Epoch 5/10\n",
            "860/860 [==============================] - 61s 71ms/step - loss: 0.4489 - accuracy: 0.8324 - val_loss: 0.3190 - val_accuracy: 0.8822\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.34065 to 0.31905, saving model to model_v2.weights.best.hdf5\n",
            "Epoch 6/10\n",
            "860/860 [==============================] - 61s 71ms/step - loss: 0.4249 - accuracy: 0.8452 - val_loss: 0.3092 - val_accuracy: 0.8812\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.31905 to 0.30918, saving model to model_v2.weights.best.hdf5\n",
            "Epoch 7/10\n",
            "860/860 [==============================] - 61s 71ms/step - loss: 0.4090 - accuracy: 0.8487 - val_loss: 0.2968 - val_accuracy: 0.8928\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.30918 to 0.29680, saving model to model_v2.weights.best.hdf5\n",
            "Epoch 8/10\n",
            "860/860 [==============================] - 61s 71ms/step - loss: 0.3916 - accuracy: 0.8554 - val_loss: 0.2942 - val_accuracy: 0.8928\n",
            "\n",
            "Epoch 00008: val_loss improved from 0.29680 to 0.29423, saving model to model_v2.weights.best.hdf5\n",
            "Epoch 9/10\n",
            "860/860 [==============================] - 61s 71ms/step - loss: 0.3860 - accuracy: 0.8572 - val_loss: 0.2954 - val_accuracy: 0.8904\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 0.29423\n",
            "Epoch 10/10\n",
            "860/860 [==============================] - 61s 71ms/step - loss: 0.3728 - accuracy: 0.8621 - val_loss: 0.2871 - val_accuracy: 0.8974\n",
            "\n",
            "Epoch 00010: val_loss improved from 0.29423 to 0.28705, saving model to model_v2.weights.best.hdf5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QRT9pNDiGGNq",
        "outputId": "89e02027-dad2-4a59-b714-7f8ee220877f"
      },
      "source": [
        "score  = le_net_variant.evaluate(x_test,y_test)\n",
        "print(f'Test Accuracy is {score[1]}')"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 3s 9ms/step - loss: 0.3111 - accuracy: 0.8867\n",
            "Test Accuracy is 0.8866999745368958\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rJzwRLVFHCs-"
      },
      "source": [
        "Moving to **AlexNet**\n",
        "```\n",
        "Very Deep Convolutional NN\n",
        "Achieved with GPUs as data and computation is huge\n",
        "```\n",
        "\n",
        "* 8 Layer CNN for *ImageNet* Dataset(larger 224*224)\n",
        "* Relu as activation (**lenet** used sigmoid)\n",
        "* First Layer filters are 11*11\n",
        "* Added Image Augmentation(flipping, clipping and color change)\n",
        "* uses dropout (**lenet** used weight decay)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ct9Y1TlwHBJx"
      },
      "source": [
        "def build_alex_net():\n",
        "  model = tf.keras.Sequential()\n",
        "  #Must define input shape in first layer of NN\n",
        "  model.add(tf.keras.layers.Conv2D(filters=32,\n",
        "                                   kernel_size=11,\n",
        "                                   activation='relu',\n",
        "                                   padding= 'same',\n",
        "                                   input_shape = (28,28,1)))\n",
        "  \n",
        "  model.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
        "  model.add(tf.keras.layers.Dropout(0.3))\n",
        "\n",
        "  model.add(tf.keras.layers.Conv2D(filters=64,\n",
        "                                   kernel_size=5,\n",
        "                                   activation='relu',\n",
        "                                   padding= 'same'))\n",
        "  \n",
        "  model.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
        "  model.add(tf.keras.layers.Dropout(0.3))\n",
        "  \n",
        "  model.add(tf.keras.layers.Conv2D(filters=128,\n",
        "                                   kernel_size=3,\n",
        "                                   padding= 'same',\n",
        "                                   activation='relu'))\n",
        "  model.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
        "  model.add(tf.keras.layers.Dropout(0.3))\n",
        "\n",
        "  model.add(tf.keras.layers.Conv2D(filters=128,\n",
        "                                   kernel_size=3,\n",
        "                                   padding= 'same',\n",
        "                                   activation='relu'))\n",
        "  #model.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
        "  #model.add(tf.keras.layers.Dropout(0.3))\n",
        "\n",
        "  model.add(tf.keras.layers.Conv2D(filters=128,\n",
        "                                   kernel_size=3,\n",
        "                                   padding= 'same',\n",
        "                                   activation='relu'))\n",
        "  #model.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
        "  #model.add(tf.keras.layers.Dropout(0.3))  \n",
        "  \n",
        "  model.add(tf.keras.layers.Flatten())\n",
        "  \n",
        "  '''We need bigger fully connected layer as Output shape from flattened\n",
        "  Convolutions  is 1568'''\n",
        "\n",
        "  model.add(tf.keras.layers.Dense(2048, activation = 'relu'))\n",
        "  model.add(tf.keras.layers.Dropout(0.5))   \n",
        "  model.add(tf.keras.layers.Dense(1000, activation = 'softmax'))\n",
        "\n",
        "  model.compile(loss = 'categorical_crossentropy',\n",
        "                optimizer='adam',\n",
        "                metrics=['accuracy'])\n",
        "  return model"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MqVlPltmKJGn",
        "outputId": "4d8a7f81-be5d-4e54-ac5a-6137c9b0f69a"
      },
      "source": [
        "alexnet = build_alex_net()\n",
        "print(alexnet.summary())"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_18 (Conv2D)           (None, 28, 28, 32)        3904      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_10 (MaxPooling (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_11 (Dropout)         (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_19 (Conv2D)           (None, 14, 14, 64)        51264     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_11 (MaxPooling (None, 7, 7, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_12 (Dropout)         (None, 7, 7, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_20 (Conv2D)           (None, 7, 7, 128)         73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_12 (MaxPooling (None, 3, 3, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_13 (Dropout)         (None, 3, 3, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_21 (Conv2D)           (None, 3, 3, 128)         147584    \n",
            "_________________________________________________________________\n",
            "conv2d_22 (Conv2D)           (None, 3, 3, 128)         147584    \n",
            "_________________________________________________________________\n",
            "flatten_5 (Flatten)          (None, 1152)              0         \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 2048)              2361344   \n",
            "_________________________________________________________________\n",
            "dropout_14 (Dropout)         (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 1000)              2049000   \n",
            "=================================================================\n",
            "Total params: 4,834,536\n",
            "Trainable params: 4,834,536\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vI2_JhyXKm-q"
      },
      "source": [
        "Relu Activation\n",
        "```\n",
        "output = max(0,input)\n",
        "```\n",
        "Why?\n",
        "1. Deep Layers cause vanishing gradient problem (solved with Relu)\n",
        "2. Gradient tends to be close to zero for deeper networks (as sigmoid and tanh are flat at the beginning and end) \n",
        "3. Hence, learning is slow\n",
        "4. Sigmoid and Tanh are exponential in nature whereas RELU is piecewise linear and less costly (easier to train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H_4-iWcHLjKO"
      },
      "source": [
        "*Transfer Learning*\n",
        "\n",
        "1. Useful when you donot have sufficient \n",
        "labelled data for task\n",
        "\n",
        "2. One-Shot and Zero-shot learning\n",
        "\n",
        "3. Key driver for success of ML in Industry\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hGLIiTyUM4wM"
      },
      "source": [
        "From AlexNet to **VGG**\n",
        "\n",
        "1. Consists of VGG Block\n",
        "\n",
        "> One Block contains sequence of Convolution Layer and maxpooling layer\n",
        "\n",
        "2. Has 5 Convolutional blocks\n",
        "\n",
        "> First Two have two Conv layers\n",
        "\n",
        "> later Three have three Conv Layers\n",
        "\n",
        "> 3 Fully connected layer\n",
        "\n",
        "3. All Conv have 3 * 3 filters with 2 * 2 italicized text MaxPool\n",
        "\n",
        "4. Number of Channels remains the same\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CQMwa-vMOUGe"
      },
      "source": [
        "Synthetic Mnist with **VGG-16**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "D4b55IbmM4f9",
        "outputId": "afb44d09-4580-4d0c-ce0c-ae67f6e37579"
      },
      "source": [
        "!pip install -q kaggle\n",
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-9dc8b0aa-6a0e-448e-ade3-f41d60d52e7b\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-9dc8b0aa-6a0e-448e-ade3-f41d60d52e7b\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"vinayex2\",\"key\":\"f2a28eb042824629fed6dd52bc279b6d\"}'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JkzzKwSuKmqk"
      },
      "source": [
        "!mkdir ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0CqUG2I7KO4r",
        "outputId": "4892c83f-fdd4-4ea6-e0a7-2992b0c7e794"
      },
      "source": [
        "!kaggle datasets download -d 'prasunroy/synthetic-digits'"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading synthetic-digits.zip to /content\n",
            " 95% 221M/232M [00:01<00:00, 199MB/s]\n",
            "100% 232M/232M [00:01<00:00, 198MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OSRxtcFuQQ27"
      },
      "source": [
        "!unzip synthetic-digits.zip -d synthetic-digits"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DbPBTOk9Qq8k"
      },
      "source": [
        "Data Generators for **Real ML**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1oded8n3QqPv",
        "outputId": "488bd4b2-c8a1-4b61-f20c-9d1b270a9a7e"
      },
      "source": [
        "imagegen = tf.keras.preprocessing.image.ImageDataGenerator()\n",
        "batch_size=128\n",
        "dimen = 224\n",
        "train = imagegen.flow_from_directory('/content/synthetic-digits/synthetic_digits/imgs_train',\n",
        "                                    class_mode='categorical',\n",
        "                                    shuffle=False,\n",
        "                                    batch_size=batch_size,\n",
        "                                    target_size=(dimen,dimen))\n",
        "val = imagegen.flow_from_directory('/content/synthetic-digits/synthetic_digits/imgs_valid',\n",
        "                                    class_mode='categorical',\n",
        "                                    shuffle=False,\n",
        "                                    batch_size=batch_size,\n",
        "                                    target_size=(dimen,dimen))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 10000 images belonging to 10 classes.\n",
            "Found 2000 images belonging to 10 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sCb8lTQoRd8B"
      },
      "source": [
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Dropout\n",
        "from tensorflow.keras.layers import LeakyReLU, Input, Flatten, BatchNormalization\n",
        "\n",
        "def get_baseline_model(input_shape, \n",
        "                       kernel_size_1,\n",
        "                       leaky_relu_alpha,\n",
        "                       pool_size_1,\n",
        "                       kernel_size_2,                       \n",
        "                       pool_size_2,\n",
        "                       drop_out_rate,\n",
        "                       number_of_classes):  \n",
        "  \n",
        "  model = Sequential()\n",
        "  model.add(Input(shape=input_shape))\n",
        "\n",
        "  #Block 1\n",
        "  model.add(Conv2D(32, kernel_size=kernel_size_1))\n",
        "  model.add(LeakyReLU(alpha=leaky_relu_alpha))  \n",
        "  model.add(Conv2D(32, kernel_size=kernel_size_1))\n",
        "  model.add(LeakyReLU(alpha=leaky_relu_alpha))\n",
        "  model.add(MaxPooling2D(pool_size_1))\n",
        "\n",
        "  #Block 2\n",
        "  model.add(Conv2D(64, kernel_size=kernel_size_2))\n",
        "  model.add(LeakyReLU(alpha=leaky_relu_alpha))  \n",
        "  model.add(Conv2D(64, kernel_size=kernel_size_2))\n",
        "  model.add(LeakyReLU(alpha=leaky_relu_alpha))\n",
        "  model.add(MaxPooling2D(pool_size_2))\n",
        "\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(128))\n",
        "  model.add(LeakyReLU(alpha=leaky_relu_alpha))\n",
        "  model.add(Dropout(drop_out_rate))\n",
        "\n",
        "  model.add(Dense(number_of_classes, activation = 'softmax'))\n",
        "\n",
        "  opt = tf.keras.optimizers.Adam(learning_rate = 0.001, epsilon=0.0001)\n",
        "  model.compile(loss='categorical_crossentropy', optimizer = opt,\n",
        "                metrics=['accuracy'])\n",
        "  \n",
        "  return model\n",
        "\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qu3RmtpqUD4u",
        "outputId": "3e447c86-6474-45dd-8ca1-903124ab3083"
      },
      "source": [
        "baseline = get_baseline_model((224,224,3),\n",
        "                              7,\n",
        "                              0.01,\n",
        "                              3,\n",
        "                              3,                              \n",
        "                              2,\n",
        "                              0.3,\n",
        "                              1000)\n",
        "print(baseline.summary())"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_23\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_60 (Conv2D)           (None, 218, 218, 32)      1600      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_44 (LeakyReLU)   (None, 218, 218, 32)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_61 (Conv2D)           (None, 212, 212, 32)      50208     \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_45 (LeakyReLU)   (None, 212, 212, 32)      0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_29 (MaxPooling (None, 70, 70, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_62 (Conv2D)           (None, 68, 68, 64)        18496     \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_46 (LeakyReLU)   (None, 68, 68, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_63 (Conv2D)           (None, 66, 66, 64)        36928     \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_47 (LeakyReLU)   (None, 66, 66, 64)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_30 (MaxPooling (None, 33, 33, 64)        0         \n",
            "_________________________________________________________________\n",
            "flatten_17 (Flatten)         (None, 69696)             0         \n",
            "_________________________________________________________________\n",
            "dense_36 (Dense)             (None, 128)               8921216   \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_48 (LeakyReLU)   (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dropout_26 (Dropout)         (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_37 (Dense)             (None, 1000)              129000    \n",
            "=================================================================\n",
            "Total params: 9,157,448\n",
            "Trainable params: 9,157,448\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MISI8WfsYN4H"
      },
      "source": [
        "Using Pretrained VGG"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g2BvfH3JYNRV",
        "outputId": "7c196f64-3f8f-42b7-e134-1fa9238acd93"
      },
      "source": [
        "pretrained_model = tf.keras.applications.VGG16(include_top=False,weights='imagenet')\n",
        "pretrained_model.summary()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, None, None, 3)]   0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, None, None, 64)    1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, None, None, 64)    36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, None, None, 64)    0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, None, None, 128)   73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, None, None, 128)   147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, None, None, 128)   0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, None, None, 256)   295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, None, None, 256)   590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, None, None, 256)   590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, None, None, 256)   0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, None, None, 512)   1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, None, None, 512)   2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
            "=================================================================\n",
            "Total params: 14,714,688\n",
            "Trainable params: 14,714,688\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JsaQVWkvYzr_",
        "outputId": "4e737034-1a7f-44c2-ef72-fda94d074f0a"
      },
      "source": [
        "vgg_features_train = pretrained_model.predict(train,verbose=1)\n",
        "\n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "79/79 [==============================] - 2821s 36s/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hXcvd2PnnM_y",
        "outputId": "f3196895-f909-431d-da46-6991ce343bda"
      },
      "source": [
        "vgg_features_val = pretrained_model.predict(val,verbose=1)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "16/16 [==============================] - 561s 35s/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cRxIlHvcacjg",
        "outputId": "7501ded3-64d3-4bc7-8afd-5c2bf22a6219"
      },
      "source": [
        "print(f'Shape of Features from VGG Pretrained {vgg_features_train.shape}')"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of Features from VGG Pretrained (10000, 7, 7, 512)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vIs-xcj-ZEpE"
      },
      "source": [
        "#OHE for target column\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "train_target = to_categorical(train.labels)\n",
        "val_target = to_categorical(val.labels)\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zhj0g16zZdNo"
      },
      "source": [
        "from tensorflow.keras.layers import BatchNormalization\n",
        "\n",
        "def vgg_model():\n",
        "  #Only the final Dense Portion of the model\n",
        "\n",
        "  model = Sequential()\n",
        "  model.add(Flatten(input_shape=(7,7,512)))\n",
        "  model.add(Dense(100, activation='relu'))\n",
        "  model.add(Dropout(0.5))\n",
        "  #Normalize Output of Previous Layer for a batch\n",
        "  # Tackles values getting too large and too small\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Dense(10,activation='softmax'))\n",
        "\n",
        "  model.compile(loss='categorical_crossentropy',\n",
        "                optimizer='adam',\n",
        "                metrics=['accuracy'])\n",
        "  return model\n"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p94wCeTTaGpl",
        "outputId": "53390e3d-6980-4bfe-b85b-cc7d8c50f54a"
      },
      "source": [
        "vgg_model = vgg_model()\n",
        "vgg_model.summary()"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_1 (Flatten)          (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 100)               2508900   \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 100)               400       \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                1010      \n",
            "=================================================================\n",
            "Total params: 2,510,310\n",
            "Trainable params: 2,510,110\n",
            "Non-trainable params: 200\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Stlq6sK6osFC",
        "outputId": "5359798b-52ca-4f52-b31a-ec5738d27091"
      },
      "source": [
        "vgg_model.fit(vgg_features_train, \n",
        "              train_target,\n",
        "              epochs=20,\n",
        "              validation_data=(vgg_features_val,val_target),\n",
        "              verbose=1)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "313/313 [==============================] - 7s 18ms/step - loss: 0.8294 - accuracy: 0.7551 - val_loss: 0.1163 - val_accuracy: 0.9770\n",
            "Epoch 2/20\n",
            "313/313 [==============================] - 6s 18ms/step - loss: 0.1412 - accuracy: 0.9746 - val_loss: 0.0673 - val_accuracy: 0.9855\n",
            "Epoch 3/20\n",
            "313/313 [==============================] - 6s 18ms/step - loss: 0.0682 - accuracy: 0.9898 - val_loss: 0.0561 - val_accuracy: 0.9865\n",
            "Epoch 4/20\n",
            "313/313 [==============================] - 6s 18ms/step - loss: 0.0476 - accuracy: 0.9917 - val_loss: 0.0527 - val_accuracy: 0.9835\n",
            "Epoch 5/20\n",
            "313/313 [==============================] - 6s 19ms/step - loss: 0.0345 - accuracy: 0.9953 - val_loss: 0.0473 - val_accuracy: 0.9870\n",
            "Epoch 6/20\n",
            "313/313 [==============================] - 6s 18ms/step - loss: 0.0314 - accuracy: 0.9933 - val_loss: 0.0469 - val_accuracy: 0.9860\n",
            "Epoch 7/20\n",
            "313/313 [==============================] - 6s 18ms/step - loss: 0.0306 - accuracy: 0.9931 - val_loss: 0.0434 - val_accuracy: 0.9865\n",
            "Epoch 8/20\n",
            "313/313 [==============================] - 6s 18ms/step - loss: 0.0292 - accuracy: 0.9930 - val_loss: 0.0484 - val_accuracy: 0.9835\n",
            "Epoch 9/20\n",
            "313/313 [==============================] - 6s 18ms/step - loss: 0.0246 - accuracy: 0.9935 - val_loss: 0.0407 - val_accuracy: 0.9835\n",
            "Epoch 10/20\n",
            "313/313 [==============================] - 6s 18ms/step - loss: 0.0209 - accuracy: 0.9950 - val_loss: 0.0448 - val_accuracy: 0.9860\n",
            "Epoch 11/20\n",
            "313/313 [==============================] - 6s 18ms/step - loss: 0.0211 - accuracy: 0.9933 - val_loss: 0.0408 - val_accuracy: 0.9855\n",
            "Epoch 12/20\n",
            "313/313 [==============================] - 6s 18ms/step - loss: 0.0183 - accuracy: 0.9957 - val_loss: 0.0442 - val_accuracy: 0.9855\n",
            "Epoch 13/20\n",
            "313/313 [==============================] - 6s 18ms/step - loss: 0.0149 - accuracy: 0.9966 - val_loss: 0.0423 - val_accuracy: 0.9850\n",
            "Epoch 14/20\n",
            "313/313 [==============================] - 6s 18ms/step - loss: 0.0173 - accuracy: 0.9961 - val_loss: 0.0668 - val_accuracy: 0.9825\n",
            "Epoch 15/20\n",
            "313/313 [==============================] - 6s 18ms/step - loss: 0.0174 - accuracy: 0.9936 - val_loss: 0.0499 - val_accuracy: 0.9835\n",
            "Epoch 16/20\n",
            "313/313 [==============================] - 6s 18ms/step - loss: 0.0260 - accuracy: 0.9906 - val_loss: 0.0446 - val_accuracy: 0.9845\n",
            "Epoch 17/20\n",
            "313/313 [==============================] - 6s 18ms/step - loss: 0.0209 - accuracy: 0.9945 - val_loss: 0.0475 - val_accuracy: 0.9840\n",
            "Epoch 18/20\n",
            "313/313 [==============================] - 6s 18ms/step - loss: 0.0204 - accuracy: 0.9947 - val_loss: 0.0391 - val_accuracy: 0.9850\n",
            "Epoch 19/20\n",
            "313/313 [==============================] - 6s 18ms/step - loss: 0.0139 - accuracy: 0.9960 - val_loss: 0.0407 - val_accuracy: 0.9850\n",
            "Epoch 20/20\n",
            "313/313 [==============================] - 6s 18ms/step - loss: 0.0126 - accuracy: 0.9967 - val_loss: 0.0484 - val_accuracy: 0.9845\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fe8733cd590>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G7zOaI4FueGD"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B8vMz9QebBQM"
      },
      "source": [
        "**VGG** to **RESNet**\n",
        "\n",
        "```Problem with very deep layers\n",
        "Additional layers may not be adding much value\n",
        "Possible Reason may be vanishing gradient\n",
        "Improved with Batch Normalization\n",
        "```\n",
        "\n",
        "Another option is Residual Block\n",
        "1. Uses Skip Connections\n",
        "2. Adds output from previous layer to layer ahead\n",
        "3. Need to ensure dimensions of further layers is same as skip connection shape\n",
        "4. Can be done with using appropriate Number of Kernels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CtXq6sIGhMrr"
      },
      "source": [
        "def baseline_model():\n",
        "  model = Sequential()\n",
        "  model.add(Input(input_shape=(224,224,3)))\n",
        "  \n",
        "  #Block1\n",
        "  model.add(Conv2D(25, (5,5), activation='relu', strides=(1,1), padding='same'))\n",
        "  model.add(MaxPooling2D(pool_size=(2,2), padding='same'))\n",
        "  \n",
        "  #Block2\n",
        "  model.add(Conv2D(50, (5,5), activation='relu', strides=(2,2), padding='same'))\n",
        "  model.add(MaxPooling2D(pool_size=(2,2), padding='same'))\n",
        "  model.add(BatchNormalization())\n",
        "\n",
        "  #Block3\n",
        "  model.add(Conv2D(70, (3,3), activation='relu', strides=(2,2), padding='same'))\n",
        "  model.add(MaxPooling2D(pool_size=(2,2), padding='valid'))\n",
        "  model.add(BatchNormalization())\n",
        "\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(units=100, activation='relu'))\n",
        "  model.add(Dense(units=100, activation='relu'))\n",
        "  model.add(Dropout(0.25))\n",
        "  model.add(Dense(units=10, activation='softmax'))\n",
        "\n",
        "  model.compile(loss='categorical_crossentropy',\n",
        "                optimizer='adam', \n",
        "                metrics=['accuracy'])\n",
        "  return model"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "id": "bXkAOlFCmuIZ",
        "outputId": "f73bf022-6af0-4518-a8ea-e48171001c8b"
      },
      "source": [
        "baseline = baseline_model()\n",
        "baseline.summary()"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-91e1782c1383>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbaseline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbaseline_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mbaseline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-41-282c04c5d59f>\u001b[0m in \u001b[0;36mbaseline_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mbaseline_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0;31m#Block1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/input_layer.py\u001b[0m in \u001b[0;36mInput\u001b[0;34m(shape, batch_size, name, dtype, sparse, tensor, ragged, **kwargs)\u001b[0m\n\u001b[1;32m    294\u001b[0m                      'to Input, not both at the same time.')\n\u001b[1;32m    295\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mbatch_input_shape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m     raise ValueError('Please provide to Input either a `shape`'\n\u001b[0m\u001b[1;32m    297\u001b[0m                      \u001b[0;34m' or a `tensor` argument. Note that '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m                      \u001b[0;34m'`shape` does not include the batch '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Please provide to Input either a `shape` or a `tensor` argument. Note that `shape` does not include the batch dimension."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XSpU2paXoF72",
        "outputId": "27c7ce91-c625-4ef8-a082-c2d0ab180f3d"
      },
      "source": [
        "resnet_pretrained = tf.keras.applications.ResNet50(include_top=False,weights='imagenet')\n",
        "resnet_pretrained.summary()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"resnet50\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, None, None,  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1_pad (ZeroPadding2D)       (None, None, None, 3 0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1_conv (Conv2D)             (None, None, None, 6 9472        conv1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1_bn (BatchNormalization)   (None, None, None, 6 256         conv1_conv[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1_relu (Activation)         (None, None, None, 6 0           conv1_bn[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pad (ZeroPadding2D)       (None, None, None, 6 0           conv1_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pool (MaxPooling2D)       (None, None, None, 6 0           pool1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_conv (Conv2D)    (None, None, None, 6 4160        pool1_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_bn (BatchNormali (None, None, None, 6 256         conv2_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_relu (Activation (None, None, None, 6 0           conv2_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_conv (Conv2D)    (None, None, None, 6 36928       conv2_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_bn (BatchNormali (None, None, None, 6 256         conv2_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_relu (Activation (None, None, None, 6 0           conv2_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_conv (Conv2D)    (None, None, None, 2 16640       pool1_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_3_conv (Conv2D)    (None, None, None, 2 16640       conv2_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_bn (BatchNormali (None, None, None, 2 1024        conv2_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_3_bn (BatchNormali (None, None, None, 2 1024        conv2_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_add (Add)          (None, None, None, 2 0           conv2_block1_0_bn[0][0]          \n",
            "                                                                 conv2_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_out (Activation)   (None, None, None, 2 0           conv2_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_conv (Conv2D)    (None, None, None, 6 16448       conv2_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_bn (BatchNormali (None, None, None, 6 256         conv2_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_relu (Activation (None, None, None, 6 0           conv2_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_conv (Conv2D)    (None, None, None, 6 36928       conv2_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_bn (BatchNormali (None, None, None, 6 256         conv2_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_relu (Activation (None, None, None, 6 0           conv2_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_3_conv (Conv2D)    (None, None, None, 2 16640       conv2_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_3_bn (BatchNormali (None, None, None, 2 1024        conv2_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_add (Add)          (None, None, None, 2 0           conv2_block1_out[0][0]           \n",
            "                                                                 conv2_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_out (Activation)   (None, None, None, 2 0           conv2_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_conv (Conv2D)    (None, None, None, 6 16448       conv2_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_bn (BatchNormali (None, None, None, 6 256         conv2_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_relu (Activation (None, None, None, 6 0           conv2_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_conv (Conv2D)    (None, None, None, 6 36928       conv2_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_bn (BatchNormali (None, None, None, 6 256         conv2_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_relu (Activation (None, None, None, 6 0           conv2_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_3_conv (Conv2D)    (None, None, None, 2 16640       conv2_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_3_bn (BatchNormali (None, None, None, 2 1024        conv2_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_add (Add)          (None, None, None, 2 0           conv2_block2_out[0][0]           \n",
            "                                                                 conv2_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_out (Activation)   (None, None, None, 2 0           conv2_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_conv (Conv2D)    (None, None, None, 1 32896       conv2_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_bn (BatchNormali (None, None, None, 1 512         conv3_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_relu (Activation (None, None, None, 1 0           conv3_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_conv (Conv2D)    (None, None, None, 1 147584      conv3_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_bn (BatchNormali (None, None, None, 1 512         conv3_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_relu (Activation (None, None, None, 1 0           conv3_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_conv (Conv2D)    (None, None, None, 5 131584      conv2_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_3_conv (Conv2D)    (None, None, None, 5 66048       conv3_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_bn (BatchNormali (None, None, None, 5 2048        conv3_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_3_bn (BatchNormali (None, None, None, 5 2048        conv3_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_add (Add)          (None, None, None, 5 0           conv3_block1_0_bn[0][0]          \n",
            "                                                                 conv3_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_out (Activation)   (None, None, None, 5 0           conv3_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_conv (Conv2D)    (None, None, None, 1 65664       conv3_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_bn (BatchNormali (None, None, None, 1 512         conv3_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_relu (Activation (None, None, None, 1 0           conv3_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_conv (Conv2D)    (None, None, None, 1 147584      conv3_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_bn (BatchNormali (None, None, None, 1 512         conv3_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_relu (Activation (None, None, None, 1 0           conv3_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_3_conv (Conv2D)    (None, None, None, 5 66048       conv3_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_3_bn (BatchNormali (None, None, None, 5 2048        conv3_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_add (Add)          (None, None, None, 5 0           conv3_block1_out[0][0]           \n",
            "                                                                 conv3_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_out (Activation)   (None, None, None, 5 0           conv3_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_conv (Conv2D)    (None, None, None, 1 65664       conv3_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_bn (BatchNormali (None, None, None, 1 512         conv3_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_relu (Activation (None, None, None, 1 0           conv3_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_conv (Conv2D)    (None, None, None, 1 147584      conv3_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_bn (BatchNormali (None, None, None, 1 512         conv3_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_relu (Activation (None, None, None, 1 0           conv3_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_3_conv (Conv2D)    (None, None, None, 5 66048       conv3_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_3_bn (BatchNormali (None, None, None, 5 2048        conv3_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_add (Add)          (None, None, None, 5 0           conv3_block2_out[0][0]           \n",
            "                                                                 conv3_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_out (Activation)   (None, None, None, 5 0           conv3_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_conv (Conv2D)    (None, None, None, 1 65664       conv3_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_bn (BatchNormali (None, None, None, 1 512         conv3_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_relu (Activation (None, None, None, 1 0           conv3_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_conv (Conv2D)    (None, None, None, 1 147584      conv3_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_bn (BatchNormali (None, None, None, 1 512         conv3_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_relu (Activation (None, None, None, 1 0           conv3_block4_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_3_conv (Conv2D)    (None, None, None, 5 66048       conv3_block4_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_3_bn (BatchNormali (None, None, None, 5 2048        conv3_block4_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_add (Add)          (None, None, None, 5 0           conv3_block3_out[0][0]           \n",
            "                                                                 conv3_block4_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_out (Activation)   (None, None, None, 5 0           conv3_block4_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_conv (Conv2D)    (None, None, None, 2 131328      conv3_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_relu (Activation (None, None, None, 2 0           conv4_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_conv (Conv2D)    (None, None, None, 2 590080      conv4_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_bn (BatchNormali (None, None, None, 2 1024        conv4_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_relu (Activation (None, None, None, 2 0           conv4_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_conv (Conv2D)    (None, None, None, 1 525312      conv3_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_3_conv (Conv2D)    (None, None, None, 1 263168      conv4_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_bn (BatchNormali (None, None, None, 1 4096        conv4_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_3_bn (BatchNormali (None, None, None, 1 4096        conv4_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_add (Add)          (None, None, None, 1 0           conv4_block1_0_bn[0][0]          \n",
            "                                                                 conv4_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_out (Activation)   (None, None, None, 1 0           conv4_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_conv (Conv2D)    (None, None, None, 2 262400      conv4_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_relu (Activation (None, None, None, 2 0           conv4_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_conv (Conv2D)    (None, None, None, 2 590080      conv4_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_bn (BatchNormali (None, None, None, 2 1024        conv4_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_relu (Activation (None, None, None, 2 0           conv4_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_3_conv (Conv2D)    (None, None, None, 1 263168      conv4_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_3_bn (BatchNormali (None, None, None, 1 4096        conv4_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_add (Add)          (None, None, None, 1 0           conv4_block1_out[0][0]           \n",
            "                                                                 conv4_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_out (Activation)   (None, None, None, 1 0           conv4_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_conv (Conv2D)    (None, None, None, 2 262400      conv4_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_relu (Activation (None, None, None, 2 0           conv4_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_conv (Conv2D)    (None, None, None, 2 590080      conv4_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_bn (BatchNormali (None, None, None, 2 1024        conv4_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_relu (Activation (None, None, None, 2 0           conv4_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_3_conv (Conv2D)    (None, None, None, 1 263168      conv4_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_3_bn (BatchNormali (None, None, None, 1 4096        conv4_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_add (Add)          (None, None, None, 1 0           conv4_block2_out[0][0]           \n",
            "                                                                 conv4_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_out (Activation)   (None, None, None, 1 0           conv4_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_conv (Conv2D)    (None, None, None, 2 262400      conv4_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_relu (Activation (None, None, None, 2 0           conv4_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_conv (Conv2D)    (None, None, None, 2 590080      conv4_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_bn (BatchNormali (None, None, None, 2 1024        conv4_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_relu (Activation (None, None, None, 2 0           conv4_block4_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_3_conv (Conv2D)    (None, None, None, 1 263168      conv4_block4_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_3_bn (BatchNormali (None, None, None, 1 4096        conv4_block4_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_add (Add)          (None, None, None, 1 0           conv4_block3_out[0][0]           \n",
            "                                                                 conv4_block4_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_out (Activation)   (None, None, None, 1 0           conv4_block4_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_conv (Conv2D)    (None, None, None, 2 262400      conv4_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block5_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_relu (Activation (None, None, None, 2 0           conv4_block5_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_conv (Conv2D)    (None, None, None, 2 590080      conv4_block5_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_bn (BatchNormali (None, None, None, 2 1024        conv4_block5_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_relu (Activation (None, None, None, 2 0           conv4_block5_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_3_conv (Conv2D)    (None, None, None, 1 263168      conv4_block5_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_3_bn (BatchNormali (None, None, None, 1 4096        conv4_block5_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_add (Add)          (None, None, None, 1 0           conv4_block4_out[0][0]           \n",
            "                                                                 conv4_block5_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_out (Activation)   (None, None, None, 1 0           conv4_block5_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_conv (Conv2D)    (None, None, None, 2 262400      conv4_block5_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block6_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_relu (Activation (None, None, None, 2 0           conv4_block6_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_conv (Conv2D)    (None, None, None, 2 590080      conv4_block6_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_bn (BatchNormali (None, None, None, 2 1024        conv4_block6_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_relu (Activation (None, None, None, 2 0           conv4_block6_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_3_conv (Conv2D)    (None, None, None, 1 263168      conv4_block6_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_3_bn (BatchNormali (None, None, None, 1 4096        conv4_block6_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_add (Add)          (None, None, None, 1 0           conv4_block5_out[0][0]           \n",
            "                                                                 conv4_block6_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_out (Activation)   (None, None, None, 1 0           conv4_block6_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_conv (Conv2D)    (None, None, None, 5 524800      conv4_block6_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_bn (BatchNormali (None, None, None, 5 2048        conv5_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_relu (Activation (None, None, None, 5 0           conv5_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_conv (Conv2D)    (None, None, None, 5 2359808     conv5_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_bn (BatchNormali (None, None, None, 5 2048        conv5_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_relu (Activation (None, None, None, 5 0           conv5_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_conv (Conv2D)    (None, None, None, 2 2099200     conv4_block6_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_3_conv (Conv2D)    (None, None, None, 2 1050624     conv5_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_bn (BatchNormali (None, None, None, 2 8192        conv5_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_3_bn (BatchNormali (None, None, None, 2 8192        conv5_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_add (Add)          (None, None, None, 2 0           conv5_block1_0_bn[0][0]          \n",
            "                                                                 conv5_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_out (Activation)   (None, None, None, 2 0           conv5_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_conv (Conv2D)    (None, None, None, 5 1049088     conv5_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_bn (BatchNormali (None, None, None, 5 2048        conv5_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_relu (Activation (None, None, None, 5 0           conv5_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_conv (Conv2D)    (None, None, None, 5 2359808     conv5_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_bn (BatchNormali (None, None, None, 5 2048        conv5_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_relu (Activation (None, None, None, 5 0           conv5_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_3_conv (Conv2D)    (None, None, None, 2 1050624     conv5_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_3_bn (BatchNormali (None, None, None, 2 8192        conv5_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_add (Add)          (None, None, None, 2 0           conv5_block1_out[0][0]           \n",
            "                                                                 conv5_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_out (Activation)   (None, None, None, 2 0           conv5_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_conv (Conv2D)    (None, None, None, 5 1049088     conv5_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_bn (BatchNormali (None, None, None, 5 2048        conv5_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_relu (Activation (None, None, None, 5 0           conv5_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_conv (Conv2D)    (None, None, None, 5 2359808     conv5_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_bn (BatchNormali (None, None, None, 5 2048        conv5_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_relu (Activation (None, None, None, 5 0           conv5_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_3_conv (Conv2D)    (None, None, None, 2 1050624     conv5_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_3_bn (BatchNormali (None, None, None, 2 8192        conv5_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_add (Add)          (None, None, None, 2 0           conv5_block2_out[0][0]           \n",
            "                                                                 conv5_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_out (Activation)   (None, None, None, 2 0           conv5_block3_add[0][0]           \n",
            "==================================================================================================\n",
            "Total params: 23,587,712\n",
            "Trainable params: 23,534,592\n",
            "Non-trainable params: 53,120\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XgJNzmoTvMH3",
        "outputId": "e6a84553-bf78-4abc-e1f4-c70364cee331"
      },
      "source": [
        "res_features_train = resnet_pretrained.predict(train,verbose=1)\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "79/79 [==============================] - 965s 12s/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KxnECvBczw6N",
        "outputId": "ef7b747a-c6a1-44f3-e620-bef3892040dc"
      },
      "source": [
        "res_features_val = resnet_pretrained.predict(val,verbose=1)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "16/16 [==============================] - 201s 12s/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P-IbWMtxoSzb"
      },
      "source": [
        "def resnet_model():\n",
        "  #Only the final Dense Portion of the model\n",
        "\n",
        "  model = Sequential()\n",
        "  model.add(Flatten(input_shape=(7,7,2048)))\n",
        "  model.add(Dense(100, activation='relu'))\n",
        "  model.add(Dropout(0.5))\n",
        "  #Normalize Output of Previous Layer for a batch\n",
        "  # Tackles values getting too large and too small\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Dense(10,activation='softmax'))\n",
        "\n",
        "  model.compile(loss='categorical_crossentropy',\n",
        "                optimizer='adam',\n",
        "                metrics=['accuracy'])\n",
        "  return model"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-WYhHFKDoZeV",
        "outputId": "eb5b33e2-06aa-4f61-cf60-837e6a7e743c"
      },
      "source": [
        "resnet_last_layer = resnet_model()\n",
        "resnet_last_layer.fit(res_features_train, \n",
        "              train_target,\n",
        "              epochs=20,\n",
        "              validation_data=(res_features_val,val_target),\n",
        "              verbose=1)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "313/313 [==============================] - 22s 66ms/step - loss: 1.0011 - accuracy: 0.6997 - val_loss: 0.1367 - val_accuracy: 0.9755\n",
            "Epoch 2/20\n",
            "313/313 [==============================] - 21s 66ms/step - loss: 0.1935 - accuracy: 0.9652 - val_loss: 0.0889 - val_accuracy: 0.9780\n",
            "Epoch 3/20\n",
            "313/313 [==============================] - 20s 65ms/step - loss: 0.1029 - accuracy: 0.9825 - val_loss: 0.0664 - val_accuracy: 0.9840\n",
            "Epoch 4/20\n",
            "313/313 [==============================] - 20s 65ms/step - loss: 0.0729 - accuracy: 0.9861 - val_loss: 0.0574 - val_accuracy: 0.9835\n",
            "Epoch 5/20\n",
            "313/313 [==============================] - 20s 65ms/step - loss: 0.0556 - accuracy: 0.9874 - val_loss: 0.0715 - val_accuracy: 0.9825\n",
            "Epoch 6/20\n",
            "313/313 [==============================] - 20s 65ms/step - loss: 0.0473 - accuracy: 0.9891 - val_loss: 0.0544 - val_accuracy: 0.9805\n",
            "Epoch 7/20\n",
            "313/313 [==============================] - 20s 65ms/step - loss: 0.0496 - accuracy: 0.9869 - val_loss: 0.0477 - val_accuracy: 0.9865\n",
            "Epoch 8/20\n",
            "313/313 [==============================] - 20s 65ms/step - loss: 0.0323 - accuracy: 0.9924 - val_loss: 0.0619 - val_accuracy: 0.9795\n",
            "Epoch 9/20\n",
            "313/313 [==============================] - 20s 65ms/step - loss: 0.0354 - accuracy: 0.9902 - val_loss: 0.0534 - val_accuracy: 0.9850\n",
            "Epoch 10/20\n",
            "313/313 [==============================] - 20s 65ms/step - loss: 0.0357 - accuracy: 0.9915 - val_loss: 0.0492 - val_accuracy: 0.9840\n",
            "Epoch 11/20\n",
            "313/313 [==============================] - 20s 65ms/step - loss: 0.0301 - accuracy: 0.9911 - val_loss: 0.0462 - val_accuracy: 0.9880\n",
            "Epoch 12/20\n",
            "313/313 [==============================] - 20s 65ms/step - loss: 0.0252 - accuracy: 0.9933 - val_loss: 0.0612 - val_accuracy: 0.9815\n",
            "Epoch 13/20\n",
            "313/313 [==============================] - 20s 65ms/step - loss: 0.0318 - accuracy: 0.9883 - val_loss: 0.0524 - val_accuracy: 0.9815\n",
            "Epoch 14/20\n",
            "313/313 [==============================] - 20s 65ms/step - loss: 0.0370 - accuracy: 0.9874 - val_loss: 0.0575 - val_accuracy: 0.9825\n",
            "Epoch 15/20\n",
            "313/313 [==============================] - 20s 65ms/step - loss: 0.0334 - accuracy: 0.9895 - val_loss: 0.0520 - val_accuracy: 0.9825\n",
            "Epoch 16/20\n",
            "313/313 [==============================] - 20s 65ms/step - loss: 0.0321 - accuracy: 0.9911 - val_loss: 0.0420 - val_accuracy: 0.9815\n",
            "Epoch 17/20\n",
            "313/313 [==============================] - 20s 65ms/step - loss: 0.0335 - accuracy: 0.9901 - val_loss: 0.0577 - val_accuracy: 0.9775\n",
            "Epoch 18/20\n",
            "313/313 [==============================] - 20s 65ms/step - loss: 0.0262 - accuracy: 0.9913 - val_loss: 0.0419 - val_accuracy: 0.9840\n",
            "Epoch 19/20\n",
            "313/313 [==============================] - 20s 65ms/step - loss: 0.0266 - accuracy: 0.9925 - val_loss: 0.0469 - val_accuracy: 0.9815\n",
            "Epoch 20/20\n",
            "313/313 [==============================] - 20s 65ms/step - loss: 0.0231 - accuracy: 0.9928 - val_loss: 0.0559 - val_accuracy: 0.9800\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f2bf44ad890>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y5dI53Am5FPu"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}